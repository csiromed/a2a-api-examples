{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Query_Reformulation_with_A2A",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Query Reformulation with A2A\n",
        "This example shows how A2A facilitates query reformulation research. It implements the approach outlined by Lin et al in Trec2021, using docTTTTTquery from https://cs.uwaterloo.ca/~jimmylin/publications/Nogueira_Lin_2019_docTTTTTquery-v2.pdf."
      ],
      "metadata": {
        "id": "vRcuTh7gM9Sj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install --quiet sentencepiece transformers"
      ],
      "metadata": {
        "id": "agdbCjMjPcR6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GuZQ5H2KMAbY",
        "outputId": "a94ff0ed-dc10-4f8f-856b-abd389591797"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import sys\n",
        "import re\n",
        "import requests\n",
        "import argparse\n",
        "import warnings\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import sentencepiece\n",
        "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "sw_nltk = set(stopwords.words('english') + ['presents', 'presented', 'patient', 'show', 'shows', 'year', 'yo', 'old'])\n",
        "punct=set(\",..?()/\\-+'\\\"\")\n",
        "\n",
        "# set seed for reproducibility\n",
        "torch.manual_seed(0)\n",
        "np.random.seed(0)\n",
        "\n",
        "# hyperparameter\n",
        "n_queries = 10\n",
        "k = 60"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Wrangling Functions and Model Class Definition"
      ],
      "metadata": {
        "id": "G7WR6ZpWRq_o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_topic(topic):\n",
        "    \"\"\"remove punctuation from the topic\"\"\"\n",
        "    return re.sub(r\"[^\\w\\s.]\", \" \", topic)\n",
        "\n",
        "def store_topic_as_xml(topics, q_index=0):\n",
        "    \"\"\"Convert list of topics to XML for A2A format, then write to file. q_index: index of generated query to use\"\"\"\n",
        "    xml = '<topics task=\\\"2021 TREC Clinical Trials\\\">\\n'\n",
        "    for i in range(len(topics)):\n",
        "        xml += '\\t<topic number=\"{}\">\\n'.format(i+1)\n",
        "        xml += '\\t\\t<user_query>{}</user_query>\\n'.format(clean_topic(topics[i][q_index]))\n",
        "        xml += '\\t</topic>\\n'\n",
        "    xml += '</topics>\\n'\n",
        "    with open(\"reformulated_topics_[{}].xml\".format(q_index), \"w\", encoding=\"utf-8\") as file:\n",
        "        file.write(xml)\n",
        "\n",
        "def generate_queries(topics, n_queries=1, remove_stopwords=False):\n",
        "    \"\"\"Generate the query replacements for each topic\"\"\"\n",
        "    model = docT5query()\n",
        "    new_topics = []\n",
        "    for topic in topics:\n",
        "        clean_queries, queries = model.get_queries(topic[\"description\"], top_k=10, num_queries=n_queries)\n",
        "        \n",
        "        # replace with the expansion terms to remove stopwords and puncutation\n",
        "        if remove_stopwords:\n",
        "            clean_query_strs = []\n",
        "            for terms in clean_queries:\n",
        "                query = \" \".join(terms)\n",
        "                if len(query) == 0: # empty queries cause an error, they need to be replaced\n",
        "                    query = topic[\"description\"]\n",
        "                clean_query_strs.append(query)\n",
        "        else:\n",
        "            clean_query_strs = queries\n",
        "        \n",
        "        new_topics.append([topic[\"description\"]] + clean_query_strs)\n",
        "    return new_topics\n",
        "\n",
        "def fuse_rankings(rankings, n_topics, n_voters=1, k=60):\n",
        "    \"\"\"Calculate an overall rank for each topic using reciprocal rank fusion https://plg.uwaterloo.ca/~gvcormac/cormacksigir09-rrf.pdf\"\"\"\n",
        "    query_dfs = []\n",
        "    for query in range(n_topics):\n",
        "        # Create a table of rows: rankings for each document by the columns: voters\n",
        "        df = pd.DataFrame()\n",
        "        for voter in range(n_voters):\n",
        "            # Create a series with index doc id, value: rank\n",
        "            ranked_ids = list(map(lambda row: row[0], rankings[voter][str(query + 1)])) # the document ids in a list sorted by rank (rankings are already sorted)\n",
        "            ranks = pd.DataFrame(ranked_ids, columns=[\"doc_id\"]).set_index(\"doc_id\") # create dataframe with ids as the index\n",
        "            ranks[\"rank_{}\".format(voter)] = np.arange(ranks.shape[0]) + 1\n",
        "            \n",
        "            # Append rows to dataframe using outer join\n",
        "            df = pd.concat([df, ranks], axis=1, join=\"outer\")\n",
        "            df = df.fillna(10000) # any document that wasn't in the top 1000 ranks for a voter will have a very low score\n",
        "\n",
        "        # Calculate rank fusion score for this topic\n",
        "        recip_rank = (1/(k + df))\n",
        "        rff_score = recip_rank.sum(axis=1)\n",
        "        df[\"fusion_score\"] = rff_score\n",
        "\n",
        "        # add a numerical rank column\n",
        "        df = df.sort_values(by=\"fusion_score\", ascending=False)\n",
        "        df[\"fusion_rank\"] = np.arange(1, df.shape[0] + 1)\n",
        "        query_dfs.append(df)\n",
        "    return query_dfs"
      ],
      "metadata": {
        "id": "QhRBz-10MI0X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model Definition\n",
        "class docT5query(torch.nn.Module):\n",
        "    def __init__(self, pretrained_model_path=\"castorini/doc2query-t5-base-msmarco\", max_input_size=512, max_output_size=64):\n",
        "        super().__init__()\n",
        "        self.tokenizer = T5Tokenizer.from_pretrained(\"castorini/doc2query-t5-base-msmarco\")\n",
        "        self.model = T5ForConditionalGeneration.from_pretrained(pretrained_model_path).to(device)\n",
        "        self.max_input_size = max_input_size\n",
        "        self.max_output_size = max_output_size\n",
        "\n",
        "    def get_queries(self, doc_text, top_k=10, num_queries=10):\n",
        "        # Generate the queries using top_k sampling\n",
        "        with torch.no_grad():\n",
        "            input_ids = self.tokenizer.encode(doc_text, return_tensors='pt', truncation=True, max_length=self.max_input_size).to(device)\n",
        "            outputs = self.model.generate( # Generates using topk sampling until it reaches EOS token\n",
        "                input_ids=input_ids,\n",
        "                max_length=self.max_output_size,\n",
        "                do_sample=True,\n",
        "                top_k=top_k,\n",
        "                num_return_sequences=num_queries)\n",
        "\n",
        "        # Clean them, removing punctuation and stopwords\n",
        "        clean_queries = []\n",
        "        queries = []\n",
        "        for i in range(num_queries):\n",
        "            sent = self.tokenizer.decode(outputs[i], skip_special_tokens=True)\n",
        "            queries.append(sent)\n",
        "            sentence = [m.group().lower() for m in re.finditer(r\"[^\\W\\d_]+|\\d+|\\S\", sent)] # split sentence into tokens\n",
        "            clean_queries.append([s.lower() for s in sentence if s.lower() not in sw_nltk and s not in punct]) # keep the clean tokens\n",
        "        \n",
        "        return clean_queries, queries"
      ],
      "metadata": {
        "id": "NpvYT0byTsvu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation Functions\n",
        "def df_to_trec(df, topic_id=0, file_name=None, rank_col=\"rank\", run_name=\"ct2021_test\"):\n",
        "    \"\"\"\n",
        "    convert a single dataframe to the trec results format for scoring. \n",
        "    if file_name is passed, write the results to file, otherwise return the dataframe\n",
        "    \"\"\"\n",
        "    # Convert the ranking to a score, so other ranking columns can be used\n",
        "    trec_df = df.copy()\n",
        "    assert not np.any(trec_df[rank_col] == 0), \"ranks starting at 0 cause a division by zero error!\"\n",
        "    trec_df[\"score\"] = 1/trec_df[rank_col]\n",
        "    trec_df = trec_df.sort_values(\"score\", ascending=False)\n",
        "    trec_df = trec_df[:1000]\n",
        "\n",
        "    # Add columns in the TREC Format\n",
        "    trec_df[\"Q0\"] = \"Q0\"\n",
        "    trec_df[\"run_name\"] = run_name\n",
        "    trec_df[\"doc_id\"] = trec_df.index\n",
        "    trec_df[\"topic_id\"] = topic_id + 1\n",
        "    trec_df = trec_df.rename(columns={\"doc_id\": \"document_id\"})\n",
        "\n",
        "    trec_df = trec_df.reset_index()\n",
        "    trec_df = trec_df.reindex(columns=[\"topic_id\", \"Q0\", \"document_id\", rank_col, \"score\", \"run_name\"]) # reorder the columns\n",
        "    \n",
        "    if file_name is not None:\n",
        "        trec_df.to_csv(file_name, sep=\"\\t\", header=False, index=False)\n",
        "    return trec_df\n",
        "\n",
        "def dfs_to_trec(dfs, file_name, rank_col=\"fusion_rank\", run_name=\"ct2021_test\"):\n",
        "    \"\"\"Takes in a list of query dfs and converts them to the TREC results fromat for scoring, note the dfs must be in the same order as the topic id\"\"\"\n",
        "    results = []\n",
        "    for topic_id, df in enumerate(dfs):\n",
        "        results.append(df_to_trec(df, topic_id=topic_id, rank_col=rank_col, run_name=run_name))\n",
        "    \n",
        "    results = pd.concat(results, axis=0)\n",
        "    results.to_csv(file_name, sep=\"\\t\", header=False, index=False)"
      ],
      "metadata": {
        "id": "KJJPR0m_a8uU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Reformulate Queries, then Perform and Evaluate Retrieval"
      ],
      "metadata": {
        "id": "RUb1Q6XzVY0a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Reformulate Queries\n",
        "topics = requests.get('https://a2a.csiro.au/api/topics/ct2021').json() # Download topics\n",
        "new_topics = generate_queries(topics, n_queries=n_queries)\n",
        "\n",
        "# Perform retrieval for all reformulated queries\n",
        "rankings = []\n",
        "for i in range(n_queries + 1): # the original query is also used\n",
        "    store_topic_as_xml(new_topics, q_index=i)\n",
        "    topic_file = {'file': open('reformulated_topics_[{}].xml'.format(i),'rb')} # open the topic xml as binary\n",
        "    response = requests.post('https://a2a.csiro.au/api/bm25/ct2021?t=$user_query', files=topic_file) # Retrieve using BM25 on the reformulated queries\n",
        "    rankings.append(response.json()['rankings'])\n",
        "query_dfs = fuse_rankings(rankings, len(topics), n_voters=n_queries + 1, k=k) # aggregate rankings of each reformulation with rank fusion\n",
        "\n",
        "# Evaluate rankings\n",
        "dfs_to_trec(query_dfs, 'reformulated_fusion.results')\n",
        "files = {'file': open('reformulated_fusion.results', 'rb')}\n",
        "reranked_results_graded = requests.post('https://a2a.csiro.au/api/eval/ct2021', files=files).json()\n",
        "print(f\"Results: {reranked_results_graded}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rNCGF3JBTNe2",
        "outputId": "f8843530-2884-45c5-c275-f417a937e686"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results: {'all': {'bpref': 0.4487, 'ndcg_cut_10': 0.3035}, 'per_topic': {'1': {'bpref': 0.7612, 'ndcg_cut_10': 0.3471}, '2': {'bpref': 0.7671, 'ndcg_cut_10': 0.4525}, '3': {'bpref': 0.4113, 'ndcg_cut_10': 0.0331}, '4': {'bpref': 0.4427, 'ndcg_cut_10': 0.5965}, '5': {'bpref': 0.6014, 'ndcg_cut_10': 0.7631}, '6': {'bpref': 0.3073, 'ndcg_cut_10': 0.1625}, '7': {'bpref': 0.3757, 'ndcg_cut_10': 0.1635}, '8': {'bpref': 0.6033, 'ndcg_cut_10': 1.0}, '9': {'bpref': 0.5629, 'ndcg_cut_10': 0.1973}, '10': {'bpref': 0.7542, 'ndcg_cut_10': 0.4619}, '11': {'bpref': 0.7616, 'ndcg_cut_10': 0.5}, '12': {'bpref': 0.6668, 'ndcg_cut_10': 0.4186}, '13': {'bpref': 0.3848, 'ndcg_cut_10': 0.2646}, '14': {'bpref': 0.1871, 'ndcg_cut_10': 0.11}, '15': {'bpref': 0.2556, 'ndcg_cut_10': 0.4905}, '16': {'bpref': 0.2488, 'ndcg_cut_10': 0.2201}, '17': {'bpref': 0.6384, 'ndcg_cut_10': 0.055}, '18': {'bpref': 0.5211, 'ndcg_cut_10': 0.5347}, '19': {'bpref': 0.5575, 'ndcg_cut_10': 0.3293}, '20': {'bpref': 0.2782, 'ndcg_cut_10': 0.3301}, '21': {'bpref': 0.1228, 'ndcg_cut_10': 0.0851}, '22': {'bpref': 0.2489, 'ndcg_cut_10': 0.3341}, '23': {'bpref': 0.3231, 'ndcg_cut_10': 0.2384}, '24': {'bpref': 0.4471, 'ndcg_cut_10': 0.0318}, '25': {'bpref': 0.2254, 'ndcg_cut_10': 0.3599}, '26': {'bpref': 0.1576, 'ndcg_cut_10': 0.11}, '27': {'bpref': 0.5267, 'ndcg_cut_10': 0.1565}, '28': {'bpref': 0.2746, 'ndcg_cut_10': 0.0}, '29': {'bpref': 0.3, 'ndcg_cut_10': 0.1343}, '30': {'bpref': 0.6168, 'ndcg_cut_10': 0.3789}, '31': {'bpref': 0.3908, 'ndcg_cut_10': 0.2194}, '32': {'bpref': 0.1588, 'ndcg_cut_10': 0.0}, '33': {'bpref': 0.211, 'ndcg_cut_10': 0.2298}, '34': {'bpref': 0.1437, 'ndcg_cut_10': 0.0}, '35': {'bpref': 0.8489, 'ndcg_cut_10': 0.0678}, '36': {'bpref': 0.1822, 'ndcg_cut_10': 0.0}, '37': {'bpref': 0.8315, 'ndcg_cut_10': 0.5985}, '38': {'bpref': 0.8294, 'ndcg_cut_10': 0.3615}, '39': {'bpref': 0.6492, 'ndcg_cut_10': 0.4746}, '40': {'bpref': 0.3195, 'ndcg_cut_10': 0.3679}, '41': {'bpref': 0.5059, 'ndcg_cut_10': 0.6455}, '42': {'bpref': 0.1783, 'ndcg_cut_10': 0.1467}, '43': {'bpref': 0.7928, 'ndcg_cut_10': 0.5335}, '44': {'bpref': 0.7327, 'ndcg_cut_10': 0.5406}, '45': {'bpref': 0.8814, 'ndcg_cut_10': 0.4074}, '46': {'bpref': 0.5739, 'ndcg_cut_10': 0.2863}, '47': {'bpref': 0.1939, 'ndcg_cut_10': 0.0}, '48': {'bpref': 0.8382, 'ndcg_cut_10': 0.8914}, '49': {'bpref': 0.828, 'ndcg_cut_10': 0.7935}, '50': {'bpref': 0.1966, 'ndcg_cut_10': 0.0694}, '51': {'bpref': 0.4204, 'ndcg_cut_10': 0.2856}, '52': {'bpref': 0.4689, 'ndcg_cut_10': 0.6898}, '53': {'bpref': 0.0832, 'ndcg_cut_10': 0.0}, '54': {'bpref': 0.7479, 'ndcg_cut_10': 0.5139}, '55': {'bpref': 0.0059, 'ndcg_cut_10': 0.0}, '56': {'bpref': 0.7025, 'ndcg_cut_10': 0.336}, '57': {'bpref': 0.2735, 'ndcg_cut_10': 0.0948}, '58': {'bpref': 0.8893, 'ndcg_cut_10': 0.2259}, '59': {'bpref': 0.5326, 'ndcg_cut_10': 0.4499}, '60': {'bpref': 0.3825, 'ndcg_cut_10': 0.2201}, '61': {'bpref': 0.2301, 'ndcg_cut_10': 0.0636}, '62': {'bpref': 0.4986, 'ndcg_cut_10': 0.0}, '63': {'bpref': 0.03, 'ndcg_cut_10': 0.0}, '64': {'bpref': 0.3125, 'ndcg_cut_10': 0.1492}, '65': {'bpref': 0.0546, 'ndcg_cut_10': 0.0}, '66': {'bpref': 0.1046, 'ndcg_cut_10': 0.0474}, '67': {'bpref': 0.6588, 'ndcg_cut_10': 0.4369}, '68': {'bpref': 0.4048, 'ndcg_cut_10': 0.4549}, '69': {'bpref': 0.3836, 'ndcg_cut_10': 0.2849}, '70': {'bpref': 0.3611, 'ndcg_cut_10': 0.3773}, '71': {'bpref': 0.0977, 'ndcg_cut_10': 0.0}, '72': {'bpref': 0.7986, 'ndcg_cut_10': 0.6651}, '73': {'bpref': 0.7211, 'ndcg_cut_10': 0.6501}, '74': {'bpref': 0.3846, 'ndcg_cut_10': 0.4658}, '75': {'bpref': 0.486, 'ndcg_cut_10': 0.4537}}}\n"
          ]
        }
      ]
    }
  ]
}